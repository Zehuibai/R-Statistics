# Gradient Boosting

##

### GBDT概述

{% embed url="https://www.cnblogs.com/pinard/p/6140514.html" %}

### GBDT的负梯度拟合



### GBDT回归算法



### GBDT分类算法

### Package ‘gbm’

对Freund和Schapire的AdaBoost算法以及Friedman的梯度增强机的扩展的实现。 包括最小二乘，绝对损失，t分布损失，分位数回归，逻辑，多项式逻辑，泊松，Cox比例风险部分可能性，AdaBoost指数损失，Huberized铰链损失和学习排名度量（LambdaMart）的回归方法。

Source: [https://cran.r-project.org/web/packages/gbm/gbm.pdf](https://cran.r-project.org/web/packages/gbm/gbm.pdf)

